{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6ba8d7-eb1a-4589-8d9b-42b13b89aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Dd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from networkx.algorithms.community import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a870c8e-d742-4505-9f7c-ec3c1477764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print out all the outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62708e79-e822-4894-8922-f2500adc6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "df = pd.read_csv(\"../data/pdf_metadata_and_summaries_trf.csv\")  # Replace with your actual filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835804a1-cc26-4846-8ce5-5a484bc55e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File Name', 'Metadata', 'Summary'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3ec623-d6f5-4332-ae87-19a7a6301b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = ['bank', 'fdic', 'institution']\n",
    "\n",
    "# Function to clean a sentence and return a list of cleaned words\n",
    "def clean(sentence):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords_list = stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    sentence = (unicodedata.normalize('NFKD', sentence)\n",
    "                .encode('ascii', 'ignore')\n",
    "                .decode('utf-8', 'ignore')\n",
    "                .lower())\n",
    "\n",
    "    # Remove numbers, punctuations, and any word with a single letter\n",
    "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)  # Keep only alphabetic characters and spaces\n",
    "    words = sentence.split()\n",
    "\n",
    "    # Lemmatize and filter out stopwords and single-letter words\n",
    "    word_list = [wnl.lemmatize(word) for word in words if len(word) > 1 and word not in stopwords_list]\n",
    "\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fbd6ea-9cb7-4178-97ad-1231a4cee234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract triplets (subject, predicate, object) from sentences in a dataframe column\n",
    "def extract_triplets(df, column):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and a column and returns a dataframe of triplets (subject, predicate, object) extracted from sentences.\n",
    "\n",
    "            Parameters:\n",
    "                    df (dataframe): A pandas dataframe\n",
    "                    column (str): A column name in the dataframe\n",
    "\n",
    "            Returns:\n",
    "                    triplets_df (dataframe): A dataframe with columns ['Subject', 'Predicate', 'Object', 'Filename'] containing the extracted triplets\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('en_core_web_trf')\n",
    "    triplets = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[column]\n",
    "        filename = row.get('File Name', None)\n",
    "        cleaned_sentences = [\" \".join(clean(sentence)) for sentence in nltk.sent_tokenize(str(text))]\n",
    "        cleaned_text = \" \".join(cleaned_sentences)\n",
    "        doc = nlp(cleaned_text)\n",
    "        for sentence in doc.sents:\n",
    "            subject = None\n",
    "            predicate = None\n",
    "            obj = None\n",
    "\n",
    "            for token in sentence:\n",
    "                if token.dep_ in ('nsubj', 'nsubjpass'):\n",
    "                    subject = token.text\n",
    "                elif token.dep_ == 'ROOT':\n",
    "                    predicate = token.text\n",
    "                elif token.dep_ in ('dobj', 'pobj'):\n",
    "                    obj = token.text\n",
    "\n",
    "            if subject and predicate and obj:\n",
    "                triplets.append((subject, predicate, obj, filename))\n",
    "\n",
    "    triplets_df = pd.DataFrame(triplets, columns=['Subject', 'Predicate', 'Object', 'Filename'])\n",
    "    return triplets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83024a4-39a1-4f42-a6ac-a64f7798ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dd\\OneDrive\\Documents\\_github\\bank-failures\\v312\\Lib\\site-packages\\thinc\\shims\\pytorch.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1736, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>Object</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue</td>\n",
       "      <td>provided</td>\n",
       "      <td>failure</td>\n",
       "      <td>09-003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deficiency</td>\n",
       "      <td>agreed</td>\n",
       "      <td>report</td>\n",
       "      <td>09-003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asset</td>\n",
       "      <td>conducted</td>\n",
       "      <td>quality</td>\n",
       "      <td>09-003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>institution</td>\n",
       "      <td>included</td>\n",
       "      <td>operationthe</td>\n",
       "      <td>09-003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>examination</td>\n",
       "      <td>exceeded</td>\n",
       "      <td>regulation</td>\n",
       "      <td>09-003.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject  Predicate        Object    Filename\n",
       "0        issue   provided       failure  09-003.pdf\n",
       "1   deficiency     agreed        report  09-003.pdf\n",
       "2        asset  conducted       quality  09-003.pdf\n",
       "3  institution   included  operationthe  09-003.pdf\n",
       "4  examination   exceeded    regulation  09-003.pdf"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = extract_triplets(df, \"Summary\")\n",
    "dfx.shape\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7dcf19-e979-4dca-b4e6-497dc749b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.to_csv(\"../data/triplets_trf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516d38b5-20dc-47f5-b6f4-2bbdca5d2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the knowledge graph using NetworkX and PyVis\n",
    "def visualize_knowledge_graph(triplets_df):\n",
    "    \"\"\"\n",
    "    Visualizes the knowledge graph from the triplets dataframe.\n",
    "\n",
    "            Parameters:\n",
    "                    triplets_df (dataframe): A dataframe with columns ['Subject', 'Predicate', 'Object']\n",
    "\n",
    "            Returns:\n",
    "                    None: Displays the interactive graph\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    # Add edges from triplets\n",
    "    for _, row in triplets_df.iterrows():\n",
    "        graph.add_edge(row['Subject'], row['Object'], label=row['Predicate'])\n",
    "\n",
    "    # Visualize using PyVis\n",
    "    net = Network(notebook=True, directed=True)\n",
    "    net.from_nx(graph)\n",
    "\n",
    "    # Add edge labels\n",
    "    for edge in net.edges:\n",
    "        edge['title'] = edge['label']\n",
    "\n",
    "    net.show('../data/knowledge_graph_trf.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5433b9a6-6a6c-4fab-84b6-d3c718f0fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "../data/knowledge_graph_trf.html\n"
     ]
    }
   ],
   "source": [
    "visualize_knowledge_graph(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51eda5a2-44bf-4ee4-9a1f-287b4f4086fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1736, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916ba3b-0004-4412-82a3-fc7cb4863d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
